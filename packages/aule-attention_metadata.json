{
  "name": "aule-attention",
  "version": "0.3.6",
  "summary": "FlashAttention that just works. No compilation. Any GPU. AMD ROCm, NVIDIA CUDA, Intel, Apple via Vulkan.",
  "author": null,
  "license": "MIT",
  "home_page": null,
  "download_filename": "aule_attention-0.3.6-py3-none-any.whl",
  "download_time": "2025-12-16T00:51:41.618095",
  "package_url": "https://pypi.org/project/aule-attention/"
}